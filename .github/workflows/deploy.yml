name: Snowflake Infrastructure Deploy

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  SNOWFLAKE_ACCOUNT: "TMJESFF-ED32433"
  SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
  SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
  SNOWFLAKE_ROLE: "ACCOUNTADMIN"
  SNOWFLAKE_WAREHOUSE: "COMPUTE_WH"
  S3_PATH: "s3://bucket-for-snowflake-projects/cosmetics_etl_project"

jobs:
  check_changes:
    runs-on: ubuntu-latest
    outputs:
      infra_sql: ${{ steps.filter.outputs.infra_sql }}
      infra_all: ${{ steps.filter.outputs.infra_all }}
      pipelines: ${{ steps.filter.outputs.pipelines }}
    steps:
      - uses: actions/checkout@v4
      - uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            infra_sql:
              - 'infrastructure/setup_infra.sql'
            infra_all:
              - 'infrastructure/**'
            pipelines:
              - 'pipelines/**'
              - 'orchestration/**'

  deploy:
    runs-on: ubuntu-latest
    needs: check_changes
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      # --- 1. Terraform é˜¶æ®µ ---
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init & Apply
        env:
          SNOWFLAKE_ORGANIZATION_NAME: "TMJESFF"
          SNOWFLAKE_ACCOUNT_NAME:      "ED32433"
        run: |
          cd terraform
          terraform init
          terraform import snowflake_database.cosmetics_db COSMETICS_DB_DEV || true
          terraform import snowflake_schema.cosmetics_schema "\"COSMETICS_DB_DEV\".\"COSMETICS\"" || true
          terraform apply -auto-approve

      # --- 2. Python ç¯å¢ƒå‡†å¤‡ ---
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install Dependencies
        run: |
          pip install snowflake-snowpark-python pandas
          pip install great-expectations==1.10.0

      # --- 3. æ‰§è¡Œç‰©ç†å±‚åŸºç¡€è®¾æ–½ SQL (Storage Integration, External Stage ç­‰) ---
      - name: Run Physical Infrastructure SQL
        if: needs.check_changes.outputs.infra_sql == 'true' || github.event_name == 'workflow_dispatch'
        run: |
          python -c "
          import os, re
          import snowflake.snowpark as snowpark
          session = snowpark.Session.builder.configs({
              'account': '${{ env.SNOWFLAKE_ACCOUNT }}',
              'user': '${{ env.SNOWFLAKE_USER }}',
              'password': '${{ env.SNOWFLAKE_PASSWORD }}',
              'role': '${{ env.SNOWFLAKE_ROLE }}'
          }).create()
          
          def is_valid_sql(sql):
              content = re.sub(r'--.*', '', sql)
              content = re.sub(r'/\*.*?\*/', '', content, flags=re.DOTALL)
              return len(content.strip()) > 0

          try:
              sql_file = 'infrastructure/setup_infra.sql'
              print(f'ğŸš€ æ­£åœ¨æ‰§è¡Œç‰©ç†å±‚éƒ¨ç½²: {sql_file}')
              with open(sql_file, 'r') as f:
                  queries = [q.strip() for q in f.read().split(';') if q.strip()]
                  for query in queries:
                      if is_valid_sql(query):
                          session.sql(query).collect()
              print('âœ… ç‰©ç†å±‚ SQL æ‰§è¡ŒæˆåŠŸï¼')
          except Exception as e:
              print(f'âŒ æ‰§è¡Œå¤±è´¥: {str(e)}')
              exit(1)
          finally:
              session.close()
          "

      # --- 4. è¿è¡Œ Table & Stream Setup (é€»è¾‘å±‚è¡¨ç»“æ„) ---
      - name: Run Table & Stream Setup
        if: needs.check_changes.outputs.infra_all == 'true' || github.event_name == 'workflow_dispatch'
        env:
          DEPLOY_ENV: "DEV"
        run: python infrastructure/setup_tables.py

      # --- 5. é…ç½® AWS å‡­è¯ ---
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-southeast-1

      # --- 6. ç”Ÿæˆå¹¶åŒæ­¥ GX Configs (JSON è§„åˆ™æ–‡ä»¶) ---
      - name: Generate and Sync GX Configs
        if: needs.check_changes.outputs.infra_all == 'true' || github.event_name == 'workflow_dispatch'
        run: |
          python infrastructure/setup_gx.py
          aws s3 sync /tmp/gx_configs ${{ env.S3_PATH }}/gx_configs/great_expectations/ --delete

      # --- 7. åŒæ­¥ Python ä¸šåŠ¡é€»è¾‘ä»£ç  ---
      - name: Sync Pipeline Code to S3
        if: needs.check_changes.outputs.pipelines == 'true' || github.event_name == 'workflow_dispatch'
        run: |
          aws s3 sync ./pipelines ${{ env.S3_PATH }}/python_code/ --delete

      # --- 8. æ³¨å†Œå­˜å‚¨è¿‡ç¨‹å¹¶å¯åŠ¨ Task (DAG ç¼–æ’) ---
      - name: Deploy Snowflake DAG
        if: needs.check_changes.outputs.pipelines == 'true' || github.event_name == 'workflow_dispatch'
        run: |
          python -c "
          import snowflake.snowpark as snowpark
          session = snowpark.Session.builder.configs({
              'account': '${{ env.SNOWFLAKE_ACCOUNT }}',
              'user': '${{ env.SNOWFLAKE_USER }}',
              'password': '${{ env.SNOWFLAKE_PASSWORD }}',
              'role': '${{ env.SNOWFLAKE_ROLE }}',
              'warehouse': '${{ env.SNOWFLAKE_WAREHOUSE }}',
              'database': 'COSMETICS_DB_DEV',
              'schema': 'COSMETICS'
          }).create()
          try:
              print('ğŸš€ æ­£åœ¨éƒ¨ç½² DAG (Procedures & Tasks)...')
              with open('orchestration/deploy_dags.sql', 'r') as f:
                  queries = [q.strip() for q in f.read().split(';') if q.strip()]
                  for query in queries:
                      if query:
                          session.sql(query).collect()
              print('âœ… DAG éƒ¨ç½²ä¸ Task å¯åŠ¨æˆåŠŸï¼')
          finally:
              session.close()
          "