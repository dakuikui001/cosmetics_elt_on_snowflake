from snowflake.snowpark import functions as F
import great_expectations_common as gec
import time
import re
import os

class Bronze():
    def __init__(self, env, session):
        self.session = session
        env_upper = env.upper()
        
        # 1. ç‰©ç†æ•°æ®åº“åå¯¹é½ (COSMETICS_DB_DEV)
        self.env_db = f"COSMETICS_DB_{env_upper}"
        
        # 2. ç‰©ç† Stage åå¯¹é½ (STAGE_COSMETICS_DB_DEV)
        # æ³¨æ„ï¼šè¿™é‡Œå¿…é¡»å’Œ setup_infra.sql ä¸­çš„åå­—ä¸€è‡´
        self.stage_name = f"@{self.env_db}.COSMETICS.STAGE_{self.env_db}"
        
        self.landing_path = "raw"
        
        # 3. ç‰©ç† Stream åå¯¹é½ (STREAM_TRIGGER_COSMETICS_DB_DEV)
        # ğŸ”´ è¿™æ˜¯è§£å†³â€œå¾ªç¯è§¦å‘â€å’Œâ€œä¸æ¶ˆè´¹â€çš„å…³é”®
        self.stage_stream = f"{self.env_db}.COSMETICS.STREAM_TRIGGER_COSMETICS_DB_DEV"
        
    def _get_new_files(self, table_name, pattern):
        """ä¿æŒåŸé€»è¾‘ï¼šé€šè¿‡ LIST è·å–å°šæœªå…¥åº“çš„æ–‡ä»¶"""
        files_on_stage = self.session.sql(f"LIST {self.stage_name}/{self.landing_path}").collect()
        
        all_files = [f['name'].split('/')[-1] for f in files_on_stage 
                     if f['name'].split('/')[-1].startswith(pattern) and f['name'].endswith('.csv')]
        
        try:
            # æ£€æŸ¥å·²å…¥åº“çš„æ–‡ä»¶ï¼Œé˜²æ­¢é‡å¤åŠ è½½
            processed_df = self.session.table(f"{self.env_db}.COSMETICS.{table_name}").select("SOURCE_FILE").distinct()
            processed_files = {row.SOURCE_FILE for row in processed_df.to_local_iterator()}
        except Exception:
            processed_files = set()
            
        new_files = [f for f in all_files if f not in processed_files]
        return new_files

    def _force_consume_stream(self):
        """
        ä¿æŒåŸé€»è¾‘ï¼šå¼ºåˆ¶æ¶ˆè´¹ Stream åç§»é‡ã€‚
        ä½¿ç”¨ WHERE 1=0 è§¦å‘ Snowflake Stream æŒ‡é’ˆç§»åŠ¨ã€‚
        """
        print(f"ğŸ”„ æ­£åœ¨å¼ºåˆ¶æ¶ˆè´¹ Stream ({self.stage_stream})...")
        
        consume_sql = f"""
            INSERT INTO {self.env_db}.COSMETICS.COSMETICS_BZ (SOURCE_FILE)
            SELECT 'dummy_ignore' 
            FROM {self.stage_stream}
            WHERE 1=0
        """
        
        try:
            self.session.sql(consume_sql).collect()
            print("âœ… Stream æŒ‡é’ˆå·²æˆåŠŸç§»åŠ¨ï¼ŒçŠ¶æ€å·²é‡ç½®ã€‚")
        except Exception as e:
            print(f"âš ï¸ å¼ºåˆ¶æ¶ˆè´¹ Stream å¤±è´¥: {str(e)}")

    def _read_and_process_incremental(self, schema_str, file_pattern, table_name):
        """ä¿æŒåŸé€»è¾‘ï¼šæ ¸å¿ƒå¤„ç†é€»è¾‘"""
        print(f"\n--- å¼€å§‹å¤„ç†è¡¨: {table_name} ---")
        
        new_files = self._get_new_files(table_name, file_pattern)
        if not new_files:
            print(f"â˜• {table_name}: æ²¡æœ‰æ£€æµ‹åˆ°æ–°æ–‡ä»¶ï¼Œæ¸…ç† Stream...")
            self._force_consume_stream()
            return

        print(f"ğŸ“‚ åŒ¹é…åˆ° {len(new_files)} ä¸ªæ–°æ–‡ä»¶: {new_files}")
        regex_pattern = f".*({'|'.join([re.escape(f) for f in new_files])}).*"

        try:
            col_definitions = [c.strip().split(' ') for c in schema_str.split(',')]
            column_projections = ", ".join([
                f"CAST(${i+1} AS {parts[1]}) AS {parts[0].upper()}" 
                for i, parts in enumerate(col_definitions)
            ])

            sql_query = f"""
                SELECT 
                    {column_projections},
                    METADATA$FILENAME AS SOURCE_PATH,
                    SPLIT_PART(METADATA$FILENAME, '/', -1) AS SOURCE_FILE,
                    CURRENT_TIMESTAMP() AS LOAD_TIME
                FROM {self.stage_name}/{self.landing_path}
                (
                  FILE_FORMAT => '{self.env_db}.COSMETICS.BZ_CSV_FORMAT', 
                  PATTERN => '{regex_pattern}'
                )
            """

            df = self.session.sql(sql_query)
            
            # ä¿æŒåŸé€»è¾‘ï¼šè°ƒç”¨ GX æ ¡éªŒ
            batch_id = int(time.time())
            gec.validate_and_insert_process_batch(df=df, batch_id=batch_id, table_name=table_name)
            
            # å¤„ç†åæ¸…ç©º Streamï¼Œé˜²æ­¢ Task å¾ªç¯
            self._force_consume_stream()
            print(f"ğŸš€ {table_name}: å¢é‡åŠ è½½åŠæ ¡éªŒæˆåŠŸå®Œæˆã€‚")

        except Exception as e:
            import traceback
            print(f"âŒ {table_name} å¤„ç†å¼‚å¸¸ï¼Œä¿æŒ Stream åç§»é‡ä¸å˜ä»¥å¾…é‡è¯•:")
            print(traceback.format_exc())
            
    def consume_cosmetics_bz(self):
        schema = "Label STRING, Brand STRING, Name STRING, Price DOUBLE, Rank DOUBLE, Ingredients STRING, Combination INT, Dry INT, Normal INT, Oily INT, Sensitive INT"
        self._read_and_process_incremental(schema, "cosmetics", "COSMETICS_BZ")

    def consume(self):
        """ä¿æŒåŸé€»è¾‘ï¼šåŒæ­¥ GX è§„åˆ™å¹¶æ‰§è¡Œ"""
        start = int(time.time())
        print(f"\n--- Starting Bronze Layer Processing ---")
        
        local_dir = "/tmp/gx_configs/expectations"
        os.makedirs(local_dir, exist_ok=True)
        
        # ğŸ”´ åŠ¨æ€è·å– Stage è·¯å¾„ (å¯¹é½æœ€æ–°ç‰©ç†ç¯å¢ƒ)
        stage_name_full = f"{self.env_db}.COSMETICS.STAGE_{self.env_db}"
        relative_path = "gx_configs/great_expectations/expectations"
        
        print(f"ğŸ“¥ æ­£åœ¨ä» S3 Stage (@{stage_name_full}) åŒæ­¥æ ¡éªŒè§„åˆ™...")
        
        try:
            files_df = self.session.sql(f"LIST @{stage_name_full}/{relative_path}").collect()
            for file_info in files_df:
                full_s3_path = file_info['name'] 
                if not full_s3_path.endswith('.json'): continue
                
                pure_file_name = full_s3_path.split('/')[-1]
                snowflake_path = f"@{stage_name_full}/{relative_path}/{pure_file_name}"
                
                input_stream = self.session.file.get_stream(snowflake_path)
                with open(os.path.join(local_dir, pure_file_name), "wb") as f:
                    f.write(input_stream.read())
            
            gec.BASE_PATH = local_dir
            gec.preload_all_suites()
            print(f"âœ… æ ¡éªŒè§„åˆ™åŠ è½½å®Œæˆã€‚")
            
        except Exception as e:
            print(f"âš ï¸ åŒæ­¥è§„åˆ™å‘Šè­¦ (å¯èƒ½ S3 ä¸ºç©º): {str(e)}")

        self.consume_cosmetics_bz()
        print(f"--- Completed Bronze Layer: {int(time.time()) - start} seconds ---")