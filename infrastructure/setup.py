import time
from snowflake.snowpark import Session

class SnowflakeSetupHelper():
    def __init__(self, session: Session, env: str, db_name: str):
        self.session = session
        self.env = env.upper()
        self.catalog = f"{db_name.upper()}_DB_{self.env}"
        self.db_name = db_name.upper()      
        
        # å¼•ç”¨åŸºç¡€è®¾æ–½èµ„æº (éœ€ä¸ setup_infra.sql ä¸­çš„åç§°å¯¹åº”)
        # å¦‚æœ setup_infra.sql ä¸­æ˜¯ INT_S3_COSMETICS_DB_DEVï¼Œè¿™é‡Œæ‹¼æ¥é€»è¾‘éœ€ä¸€è‡´
        self.external_volume = f'VOL_S3_{self.catalog}'
        self.stage_name = f'STAGE_{self.catalog}' 
        self.initialized = False

    def create_db(self):
        """[Step 1] ç¯å¢ƒä¸Šä¸‹æ–‡åˆ‡æ¢"""
        print(f"--- [Step 1] Setting Context for {self.catalog}.{self.db_name} ---")
        self.session.sql(f"CREATE DATABASE IF NOT EXISTS {self.catalog}").collect()
        self.session.use_database(self.catalog)
        self.session.sql(f"CREATE SCHEMA IF NOT EXISTS {self.db_name}").collect()
        self.session.use_schema(self.db_name)
        print(f"âœ“ Current Context: {self.session.get_current_database()}.{self.session.get_current_schema()}")

    def _create_iceberg_table(self, table_name, columns_sql, location):
        """
        å†…éƒ¨æ–¹æ³•ï¼šåˆ›å»º Iceberg è¡¨å¹¶æ¿€æ´»å˜æ›´è¿½è¸ª
        ä¿®æ­£ç‚¹ï¼šé’ˆå¯¹ Iceberg è¡¨ä½¿ç”¨ ALTER ICEBERG TABLE è¯­æ³•
        """
        if not location.endswith('/'):
            location += '/'
            
        print(f"Creating Iceberg table {table_name} at {location}...", end='')
        
        # 1. åˆ›å»ºè¡¨ (å—ç®¡æ¨¡å¼)
        self.session.sql(f"""
            CREATE OR REPLACE ICEBERG TABLE {self.catalog}.{self.db_name}.{table_name} (
                {columns_sql}
            )
            CATALOG = 'SNOWFLAKE'
            EXTERNAL_VOLUME = '{self.external_volume}'
            BASE_LOCATION = '{location}'
            COMMENT = 'Managed Iceberg Table in Medallion Architecture'
        """).collect()

        # ğŸ”´ å…³é”®ä¿®å¤ï¼šIceberg ä¸“å±è¯­æ³•
        # å¿…é¡»ä½¿ç”¨ ALTER ICEBERG TABLE å¦åˆ™ä¼šæŠ¥ 091367 (42601) é”™è¯¯
        print(f" Activating Change Tracking for {table_name}...", end='')
        self.session.sql(f"ALTER ICEBERG TABLE {self.catalog}.{self.db_name}.{table_name} SET CHANGE_TRACKING = TRUE").collect()
        
        print("Done (Change Tracking Enabled)")

    def _create_stream(self, stream_name, table_name):
        """å†…éƒ¨æ–¹æ³•ï¼šåˆ›å»ºè¡¨çº§ Stream"""
        print(f"Creating Stream {stream_name} on {table_name}...", end='')
        # ç¡®ä¿åœ¨ Table å¼€å¯ CHANGE_TRACKING ä¹‹ååˆ›å»º
        self.session.sql(f"""
            CREATE OR REPLACE STREAM {self.catalog}.{self.db_name}.{stream_name}
            ON TABLE {self.catalog}.{self.db_name}.{table_name}
            SHOW_INITIAL_ROWS = TRUE
        """).collect()
        print("Done")

    def setup(self):
        """éƒ¨ç½² Medallion æ¶æ„æ‰€æœ‰é€»è¾‘è¡¨å’Œæµå¯¹è±¡"""
        start = int(time.time())
        print(f"\nğŸš€ Starting Snowflake Logical Setup for: {self.catalog}")
        
        self.create_db()

        # 1. Bronze å±‚ (å»ºè¡¨ + å¼€å¯è¿½è¸ª + å»ºæµ)
        self._create_iceberg_table(
            "COSMETICS_BZ", 
            "LABEL STRING, BRAND STRING, NAME STRING, PRICE DOUBLE, RANK DOUBLE, INGREDIENTS STRING, COMBINATION INTEGER, DRY INTEGER, NORMAL INTEGER, OILY INTEGER, SENSITIVE INTEGER, LOAD_TIME TIMESTAMP, SOURCE_FILE STRING", 
            "medallion/bronze/cosmetics_bz/"
        )
        self._create_stream("COSMETICS_BZ_STREAM", "COSMETICS_BZ")

        # 2. Silver å±‚ (å»ºè¡¨ + å¼€å¯è¿½è¸ª + å»ºæµ)
        self._create_iceberg_table(
            "COSMETICS_SL", 
            "LABEL STRING, BRAND STRING, NAME STRING, PRICE DOUBLE, RANK DOUBLE, INGREDIENTS STRING, COMBINATION INTEGER, DRY INTEGER, NORMAL INTEGER, OILY INTEGER, SENSITIVE INTEGER, CLEANSED_TIME TIMESTAMP", 
            "medallion/silver/cosmetics_sl/"
        )
        self._create_stream("COSMETICS_SL_STREAM", "COSMETICS_SL")

        # 3. Gold å±‚ (åˆ†æå±‚é€šå¸¸ä¸éœ€è¦ Streamï¼Œä»…å»ºè¡¨å¹¶å¼€å¯è¿½è¸ªä»¥å¤‡åç”¨)
        gold_tables = {
            "FACT_COSMETICS_GL": "NAME STRING, LABEL STRING, BRAND STRING, PRICE DOUBLE, RANK DOUBLE, INGREDIENTS STRING, UPDATE_TIME TIMESTAMP",
            "DIM_BRAND_GL": "BRAND STRING, UPDATE_TIME TIMESTAMP",
            "DIM_LABEL_GL": "LABEL STRING, UPDATE_TIME TIMESTAMP",
            "DIM_ATTRIBUTE_GL": "NAME STRING, ATTRIBUTE STRING, UPDATE_TIME TIMESTAMP"
        }
        for name, ddl in gold_tables.items():
            self._create_iceberg_table(name, ddl, f"medallion/gold/{name.lower()}/")

        # 4. Data Quality éš”ç¦»è¡¨
        self._create_iceberg_table(
            "DATA_QUALITY_QUARANTINE",
            "TABLE_NAME STRING, GX_BATCH_ID STRING, VIOLATED_RULES STRING, RAW_DATA STRING, INGESTION_TIME TIMESTAMP",
            "medallion/quarantine/data_quality_quarantine/"
        )

        print(f"âœ… Setup completed in {int(time.time()) - start} seconds")

    def cleanup(self):
        """ç‰©ç†çº§å½»åº•æ¸…ç†ï¼šåˆ é™¤è¡¨å¹¶å°è¯•ç§»é™¤ S3 ç‰©ç†æ–‡ä»¶"""
        print(f"\n--- Starting Full Physical Cleanup ---")
        full_path = f"{self.catalog}.{self.db_name}"
        
        # å¿…é¡»å…ˆåˆ é™¤è¡¨ (CASCADE ä¼šè¿å¸¦åˆ é™¤ Stream)
        tables = [
            "COSMETICS_BZ", "COSMETICS_SL", "FACT_COSMETICS_GL", 
            "DIM_BRAND_GL", "DIM_LABEL_GL", "DIM_ATTRIBUTE_GL", 
            "DATA_QUALITY_QUARANTINE"
        ]
        for t in tables:
            print(f"Dropping table {t}... ", end='')
            self.session.sql(f"DROP TABLE IF EXISTS {full_path}.{t} CASCADE").collect()
            print("Done")

        # å°è¯•ç§»é™¤ S3 ä¸Šçš„ç‰©ç†æ®‹ç•™ (Medallion ç›®å½•ä¸‹æ‰€æœ‰å†…å®¹)
        print(f"Attempting S3 physical cleanup via REMOVE...", end='')
        try:
            full_stage_path = f"@{full_path}.{self.stage_name}"
            self.session.sql(f"REMOVE {full_stage_path}/medallion/").collect()
            print("Done")
        except Exception as e:
            print(f"Notice: S3 path cleanup skipped or handled by Snowflake. {e}")

        print("âœ“ Cleanup finished.")

    def validate(self):
        """ç¯å¢ƒéªŒè¯"""
        print(f"\n--- [Step 3] Validating Environment for {self.catalog}.{self.db_name} ---")
        
        expected_tables = [
            "COSMETICS_BZ", "COSMETICS_SL", 
            "FACT_COSMETICS_GL", "DIM_BRAND_GL", "DIM_LABEL_GL", "DIM_ATTRIBUTE_GL",
            "DATA_QUALITY_QUARANTINE"
        ]
        expected_streams = ["COSMETICS_BZ_STREAM", "COSMETICS_SL_STREAM"]
        
        missing_objects = []

        try:
            self.session.use_database(self.catalog)
            self.session.use_schema(self.db_name)

            existing_tables = [row['name'] for row in self.session.sql(f"SHOW TABLES IN SCHEMA {self.db_name}").collect()]
            for table in expected_tables:
                if table.upper() in [t.upper() for t in existing_tables]:
                    print(f"  âœ“ Table {table} exists.")
                else:
                    print(f"  âœ• Table {table} is MISSING!")
                    missing_objects.append(table)

            existing_streams = [row['name'] for row in self.session.sql(f"SHOW STREAMS IN SCHEMA {self.db_name}").collect()]
            for stream in expected_streams:
                if stream.upper() in [s.upper() for s in existing_streams]:
                    print(f"  âœ“ Stream {stream} exists.")
                else:
                    print(f"  âœ• Stream {stream} is MISSING!")
                    missing_objects.append(stream)

            if not missing_objects:
                print(f"\nâœ… All {len(expected_tables)} tables and {len(expected_streams)} streams are verified.")
                return True
            else:
                return False

        except Exception as e:
            print(f"âœ• Critical Error during validation: {e}")
            return False