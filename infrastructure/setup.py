import time
from snowflake.snowpark import Session

class SnowflakeSetupHelper():
    def __init__(self, session: Session, env: str, db_name: str):
        self.session = session
        self.catalog = f"{db_name.upper()}_DB_{env.upper()}"
        self.db_name = db_name.upper()      
        
        # å¼•ç”¨åŸºç¡€è®¾æ–½èµ„æº
        self.external_volume = f'VOL_S3_{self.catalog}'
        self.stage_name = f'STAGE_{self.catalog}' # å¿…é¡»ä¸ setup_infra.sql ä¸€è‡´
        self.initialized = False

    def create_db(self):
        """[Step 1] ç¯å¢ƒä¸Šä¸‹æ–‡åˆ‡æ¢"""
        print(f"--- [Step 1] Setting Context for {self.catalog}.{self.db_name} ---")
        self.session.sql(f"CREATE DATABASE IF NOT EXISTS {self.catalog}").collect()
        self.session.use_database(self.catalog)
        self.session.sql(f"CREATE SCHEMA IF NOT EXISTS {self.db_name}").collect()
        self.session.use_schema(self.db_name)
        print(f"âœ“ Current Context: {self.session.get_current_database()}.{self.session.get_current_schema()}")

    def _create_iceberg_table(self, table_name, columns_sql, location):
        """å†…éƒ¨æ–¹æ³•ï¼šåˆ›å»º Iceberg è¡¨ (å—ç®¡æ¨¡å¼)"""
        if not location.endswith('/'):
            location += '/'
            
        print(f"Creating Iceberg table {table_name} at {location}...", end='')
        self.session.sql(f"""
            CREATE OR REPLACE ICEBERG TABLE {self.catalog}.{self.db_name}.{table_name} (
                {columns_sql}
            )
            CATALOG = 'SNOWFLAKE'
            EXTERNAL_VOLUME = '{self.external_volume}'
            BASE_LOCATION = '{location}'
            COMMENT = 'Managed Iceberg Table in Medallion Architecture'
        """).collect()
        print("Done")

    def _create_stream(self, stream_name, table_name):
        """å†…éƒ¨æ–¹æ³•ï¼šåˆ›å»ºè¡¨çº§ Stream"""
        print(f"Creating Stream {stream_name} on {table_name}...", end='')
        self.session.sql(f"""
            CREATE OR REPLACE STREAM {self.catalog}.{self.db_name}.{stream_name}
            ON TABLE {self.catalog}.{self.db_name}.{table_name}
            SHOW_INITIAL_ROWS = TRUE
        """).collect()
        print("Done")

    def setup(self):
        """éƒ¨ç½² Medallion æ¶æ„æ‰€æœ‰é€»è¾‘è¡¨å’Œæµå¯¹è±¡"""
        start = int(time.time())
        print(f"\nğŸš€ Starting Snowflake Logical Setup for: {self.catalog}")
        
        self.create_db()

        # ğŸ”´ å…³é”®ä¼˜åŒ–ï¼šä¸ºæ¯ä¸€å±‚æŒ‡å®šè¡¨çº§å­ç›®å½•ï¼Œé˜²æ­¢ S3 è·¯å¾„ä¹±ç  (imOscMoc ç­‰åç¼€)
        # 1. Bronze å±‚
        self._create_iceberg_table(
            "COSMETICS_BZ", 
            "LABEL STRING, BRAND STRING, NAME STRING, PRICE DOUBLE, RANK DOUBLE, INGREDIENTS STRING, COMBINATION INTEGER, DRY INTEGER, NORMAL INTEGER, OILY INTEGER, SENSITIVE INTEGER, LOAD_TIME TIMESTAMP, SOURCE_FILE STRING", 
            "medallion/bronze/cosmetics_bz/"
        )
        self._create_stream("COSMETICS_BZ_STREAM", "COSMETICS_BZ")

        # 2. Silver å±‚
        self._create_iceberg_table(
            "COSMETICS_SL", 
            "LABEL STRING, BRAND STRING, NAME STRING, PRICE DOUBLE, RANK DOUBLE, INGREDIENTS STRING, COMBINATION INTEGER, DRY INTEGER, NORMAL INTEGER, OILY INTEGER, SENSITIVE INTEGER, CLEANSED_TIME TIMESTAMP", 
            "medallion/silver/cosmetics_sl/"
        )
        self._create_stream("COSMETICS_SL_STREAM", "COSMETICS_SL")

        # 3. Gold å±‚
        gold_tables = {
            "FACT_COSMETICS_GL": "NAME STRING, LABEL STRING, BRAND STRING, PRICE DOUBLE, RANK DOUBLE, INGREDIENTS STRING, UPDATE_TIME TIMESTAMP",
            "DIM_BRAND_GL": "BRAND STRING, UPDATE_TIME TIMESTAMP",
            "DIM_LABEL_GL": "LABEL STRING, UPDATE_TIME TIMESTAMP",
            "DIM_ATTRIBUTE_GL": "NAME STRING, ATTRIBUTE STRING, UPDATE_TIME TIMESTAMP"
        }
        for name, ddl in gold_tables.items():
            self._create_iceberg_table(name, ddl, f"medallion/gold/{name.lower()}/")

        # 4. Data Quality
        self._create_iceberg_table(
            "DATA_QUALITY_QUARANTINE",
            "TABLE_NAME STRING, GX_BATCH_ID STRING, VIOLATED_RULES STRING, RAW_DATA STRING, INGESTION_TIME TIMESTAMP",
            "medallion/quarantine/data_quality_quarantine/"
        )

        print(f"âœ… Setup completed in {int(time.time()) - start} seconds")

    def cleanup(self):
        """ç‰©ç†çº§å½»åº•æ¸…ç†ï¼šåˆ é™¤è¡¨å¹¶å°è¯•ç§»é™¤ S3 ç‰©ç†æ–‡ä»¶"""
        print(f"\n--- Starting Full Physical Cleanup ---")
        full_path = f"{self.catalog}.{self.db_name}"
        
        # ğŸ”´ ä¿®æ­£ï¼šå¿…é¡»å…ˆåˆ é™¤è¡¨ (CASCADE é¡ºå¸¦åˆ é™¤ Stream)ï¼Œæ‰èƒ½é‡Šæ”¾ S3 è·¯å¾„
        tables = [
            "COSMETICS_BZ", "COSMETICS_SL", "FACT_COSMETICS_GL", 
            "DIM_BRAND_GL", "DIM_LABEL_GL", "DIM_ATTRIBUTE_GL", 
            "DATA_QUALITY_QUARANTINE"
        ]
        for t in tables:
            print(f"Dropping table {t}... ", end='')
            self.session.sql(f"DROP TABLE IF EXISTS {full_path}.{t} CASCADE").collect()
            print("Done")

        # ğŸ”´ ä¿®æ­£ï¼šå°è¯•ç§»é™¤ S3 ä¸Šçš„ç‰©ç†æ®‹ç•™
        print(f"Attempting S3 physical cleanup via REMOVE...", end='')
        try:
            # è·¯å¾„ï¼š@DB.SCHEMA.STAGE_NAME
            full_stage_path = f"@{full_path}.{self.stage_name}"
            self.session.sql(f"REMOVE {full_stage_path}/medallion/").collect()
            print("Done")
        except Exception as e:
            print(f"Notice: S3 path cleanup handled by Snowflake or already empty. {e}")

        print("âœ“ Cleanup finished.")

    def validate(self):
        """ç¯å¢ƒéªŒè¯ï¼šé€ä¸€æ£€æŸ¥ Medallion æ¶æ„çš„å…³é”®å¯¹è±¡"""
        print(f"\n--- [Step 3] Validating Environment for {self.catalog}.{self.db_name} ---")
        
        expected_tables = [
            "COSMETICS_BZ", "COSMETICS_SL", 
            "FACT_COSMETICS_GL", "DIM_BRAND_GL", "DIM_LABEL_GL", "DIM_ATTRIBUTE_GL",
            "DATA_QUALITY_QUARANTINE"
        ]
        expected_streams = ["COSMETICS_BZ_STREAM", "COSMETICS_SL_STREAM"]
        
        missing_objects = []

        try:
            self.session.use_database(self.catalog)
            self.session.use_schema(self.db_name)

            # 1. éªŒè¯è¡¨ (ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼æå–è¡¨å)
            existing_tables = [row['name'] for row in self.session.sql(f"SHOW TABLES IN SCHEMA {self.db_name}").collect()]
            for table in expected_tables:
                if table in existing_tables:
                    print(f"  âœ“ Table {table} exists.")
                else:
                    print(f"  âœ• Table {table} is MISSING!")
                    missing_objects.append(table)

            # 2. éªŒè¯æµ
            existing_streams = [row['name'] for row in self.session.sql(f"SHOW STREAMS IN SCHEMA {self.db_name}").collect()]
            for stream in expected_streams:
                if stream in existing_streams:
                    print(f"  âœ“ Stream {stream} exists.")
                else:
                    print(f"  âœ• Stream {stream} is MISSING!")
                    missing_objects.append(stream)

            if not missing_objects:
                print(f"\nâœ… All {len(expected_tables)} tables and {len(expected_streams)} streams are verified.")
                return True
            else:
                print(f"\nâŒ Validation Failed. Missing: {', '.join(missing_objects)}")
                return False

        except Exception as e:
            print(f"âœ• Critical Error during validation: {e}")
            return False